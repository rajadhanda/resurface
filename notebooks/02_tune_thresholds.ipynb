{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tune Classification Thresholds\n",
        "\n",
        "This notebook helps you sweep thresholds and plot precision/recall per class.\n",
        "\n",
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Add src to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.eval import evaluate_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sweep Thresholds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different thresholds\n",
        "thresholds = np.arange(0.0, 10.0, 0.5)\n",
        "results = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    metrics = evaluate_dataset(threshold=threshold)\n",
        "    if metrics.get(\"num_samples\", 0) > 0:\n",
        "        results.append({\n",
        "            \"threshold\": threshold,\n",
        "            \"accuracy\": metrics[\"overall_accuracy\"],\n",
        "            **metrics[\"per_class_precision\"],\n",
        "            **{f\"recall_{k}\": v for k, v in metrics[\"per_class_recall\"].items()}\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(results_df) > 0:\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
        "    \n",
        "    # Plot precision\n",
        "    axes[0].plot(results_df[\"threshold\"], results_df[\"recipe\"], label=\"Recipe\", marker=\"o\")\n",
        "    axes[0].plot(results_df[\"threshold\"], results_df[\"workout\"], label=\"Workout\", marker=\"s\")\n",
        "    axes[0].plot(results_df[\"threshold\"], results_df[\"quote\"], label=\"Quote\", marker=\"^\")\n",
        "    axes[0].set_xlabel(\"Threshold\")\n",
        "    axes[0].set_ylabel(\"Precision\")\n",
        "    axes[0].set_title(\"Precision vs Threshold\")\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # Plot recall\n",
        "    axes[1].plot(results_df[\"threshold\"], results_df[\"recall_recipe\"], label=\"Recipe\", marker=\"o\")\n",
        "    axes[1].plot(results_df[\"threshold\"], results_df[\"recall_workout\"], label=\"Workout\", marker=\"s\")\n",
        "    axes[1].plot(results_df[\"threshold\"], results_df[\"recall_quote\"], label=\"Quote\", marker=\"^\")\n",
        "    axes[1].set_xlabel(\"Threshold\")\n",
        "    axes[1].set_ylabel(\"Recall\")\n",
        "    axes[1].set_title(\"Recall vs Threshold\")\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Find best threshold (highest accuracy)\n",
        "    best_idx = results_df[\"accuracy\"].idxmax()\n",
        "    best_threshold = results_df.loc[best_idx, \"threshold\"]\n",
        "    print(f\"Best threshold: {best_threshold:.2f}\")\n",
        "    print(f\"Best accuracy: {results_df.loc[best_idx, 'accuracy']:.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
